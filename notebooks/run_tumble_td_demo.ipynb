{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Run/Tumble Temporal-Derivative Demo\n",
    "\n",
    "This notebook demonstrates the run-and-tumble temporal-derivative policy on the oriented run/tumble action space.\n",
    "- RUN (0): keep heading and move forward when dC â‰¥ threshold\n",
    "- TUMBLE (1): reset heading uniformly at random and move forward in one step when dC < threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure repo 'src' is on sys.path when running from notebooks/\n",
    "import sys, pathlib\n",
    "\n",
    "repo_root = pathlib.Path.cwd()\n",
    "if not (repo_root / \"src\").exists():\n",
    "    repo_root = repo_root.parent\n",
    "sys.path.insert(0, str(repo_root / \"src\"))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "mpl.use(\"module://matplotlib_inline.backend_inline\")\n",
    "set_matplotlib_formats(\"png\")\n",
    "from IPython.display import display\n",
    "\n",
    "import plume_nav_sim as pns\n",
    "from plume_nav_sim.policies.run_tumble_td import RunTumbleTemporalDerivativePolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment (matches other demos)\n",
    "grid_size = (64, 64)\n",
    "source_location = (48, 48)\n",
    "start_location = (16, 16)\n",
    "max_steps = 500\n",
    "seed = 123\n",
    "\n",
    "env = pns.make_env(\n",
    "    grid_size=grid_size,\n",
    "    source_location=source_location,\n",
    "    start_location=start_location,\n",
    "    max_steps=max_steps,\n",
    "    action_type=\"run_tumble\",\n",
    "    observation_type=\"concentration\",\n",
    "    reward_type=\"step_penalty\",\n",
    "    render_mode=\"rgb_array\",\n",
    ")\n",
    "\n",
    "policy = RunTumbleTemporalDerivativePolicy(threshold=1e-6, eps_seed=seed)\n",
    "obs, info = env.reset(seed=seed)\n",
    "policy.reset(seed=seed)\n",
    "\n",
    "positions = []\n",
    "actions = []\n",
    "concs = []\n",
    "dcs = []\n",
    "last_c = None\n",
    "total_reward = 0.0\n",
    "\n",
    "for _ in range(env.max_steps):\n",
    "    a = int(policy.select_action(obs))\n",
    "    actions.append(a)\n",
    "    obs, reward, term, trunc, step_info = env.step(a)\n",
    "    total_reward += float(reward)\n",
    "    c = float(obs[0])\n",
    "    concs.append(c)\n",
    "    if last_c is None:\n",
    "        dcs.append(0.0)\n",
    "    else:\n",
    "        dcs.append(c - last_c)\n",
    "    last_c = c\n",
    "    pos = step_info.get(\"agent_xy\") if isinstance(step_info, dict) else None\n",
    "    if pos is not None:\n",
    "        positions.append(tuple(pos))\n",
    "    if term or trunc:\n",
    "        break\n",
    "\n",
    "print(\"Steps:\", len(actions), \"Total reward:\", total_reward)\n",
    "\n",
    "# Final frame and overlay\n",
    "frame = env.render(\"rgb_array\")\n",
    "grid_w, grid_h = getattr(env, \"grid_size\", (frame.shape[1], frame.shape[0]))\n",
    "sx, sy = getattr(env, \"source_location\", (grid_w // 2, grid_h // 2))\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.imshow(frame)\n",
    "ax.set_xlim(0, grid_w)\n",
    "ax.set_ylim(grid_h, 0)\n",
    "if positions:\n",
    "    xs = [p[0] for p in positions]\n",
    "    ys = [p[1] for p in positions]\n",
    "    ax.plot(xs, ys, \"-o\", color=\"yellow\", markersize=2, linewidth=1)\n",
    "    ax.scatter([xs[0]], [ys[0]], c=\"lime\", s=36, marker=\"^\", label=\"start\")\n",
    "    ax.scatter([xs[-1]], [ys[-1]], c=\"magenta\", s=30, label=\"end\")\n",
    "ax.scatter(\n",
    "    [sx],\n",
    "    [sy],\n",
    "    marker=\"s\",\n",
    "    s=60,\n",
    "    facecolors=\"none\",\n",
    "    edgecolors=\"red\",\n",
    "    linewidths=1.5,\n",
    "    label=\"source\",\n",
    ")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_title(\"Run/Tumble TD: final frame with trajectory\")\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action counts and time series\n",
    "import numpy as np\n",
    "\n",
    "run_count = int(np.sum(np.array(actions) == 0))\n",
    "tumble_count = int(np.sum(np.array(actions) == 1))\n",
    "print(\"RUN:\", run_count, \"TUMBLE:\", tumble_count)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax[0].bar([\"RUN\", \"TUMBLE\"], [run_count, tumble_count], color=[\"#4caf50\", \"#ff9800\"])\n",
    "ax[0].set_title(\"Action counts\")\n",
    "ts = np.arange(len(concs))\n",
    "ax[1].plot(ts, concs, label=\"c\")\n",
    "ax[1].plot(ts, dcs, label=\"dc\")\n",
    "ax[1].set_title(\"Concentration and dC\")\n",
    "ax[1].legend()\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plume-nav-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
