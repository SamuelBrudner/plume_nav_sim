{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Run/Tumble TD with runner (same simulation)\n",
    "\n",
    "Companion to the manual run_tumble_td demo. Uses runner.stream to step the exact same environment and policy, and plots the resulting trajectory and action statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path and plotting setup\n",
    "import sys, pathlib\n",
    "\n",
    "repo_root = pathlib.Path.cwd()\n",
    "if not (repo_root / \"src\").exists():\n",
    "    repo_root = repo_root.parent\n",
    "sys.path.insert(0, str(repo_root / \"src\"))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "mpl.use(\"module://matplotlib_inline.backend_inline\")\n",
    "set_matplotlib_formats(\"png\")\n",
    "from IPython.display import display\n",
    "\n",
    "import plume_nav_sim as pns\n",
    "from plume_nav_sim.policies.run_tumble_td import RunTumbleTemporalDerivativePolicy\n",
    "from plume_nav_sim.runner import runner as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same configuration as the manual demo\n",
    "grid_size = (64, 64)\n",
    "source_location = (48, 48)\n",
    "start_location = (16, 16)\n",
    "max_steps = 500\n",
    "seed = 123\n",
    "\n",
    "env = pns.make_env(\n",
    "    grid_size=grid_size,\n",
    "    source_location=source_location,\n",
    "    start_location=start_location,\n",
    "    max_steps=max_steps,\n",
    "    action_type=\"run_tumble\",\n",
    "    observation_type=\"concentration\",\n",
    "    reward_type=\"step_penalty\",\n",
    "    render_mode=\"rgb_array\",\n",
    ")\n",
    "\n",
    "policy = RunTumbleTemporalDerivativePolicy(threshold=1e-6, eps_seed=seed)\n",
    "\n",
    "# Collect events via runner.stream\n",
    "positions = []\n",
    "actions = []\n",
    "concs = []\n",
    "dcs = []\n",
    "last_c = None\n",
    "total_reward = 0.0\n",
    "final_frame = None\n",
    "for ev in r.stream(env, policy, seed=seed, render=True):\n",
    "    actions.append(int(ev.action))\n",
    "    c = float(ev.obs[0])\n",
    "    concs.append(c)\n",
    "    if last_c is None:\n",
    "        dcs.append(0.0)\n",
    "    else:\n",
    "        dcs.append(c - last_c)\n",
    "    last_c = c\n",
    "    if isinstance(ev.info, dict) and \"agent_xy\" in ev.info:\n",
    "        positions.append(tuple(ev.info[\"agent_xy\"]))\n",
    "    total_reward += float(ev.reward)\n",
    "    if ev.frame is not None:\n",
    "        final_frame = ev.frame\n",
    "\n",
    "print(\"Steps:\", len(actions), \"Total reward:\", total_reward)\n",
    "\n",
    "# Trajectory overlay\n",
    "frame = final_frame if isinstance(final_frame, np.ndarray) else env.render(\"rgb_array\")\n",
    "grid_w, grid_h = grid_size\n",
    "sx, sy = source_location\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.imshow(frame)\n",
    "ax.set_xlim(0, grid_w)\n",
    "ax.set_ylim(grid_h, 0)\n",
    "if positions:\n",
    "    xs = [p[0] for p in positions]\n",
    "    ys = [p[1] for p in positions]\n",
    "    ax.plot(xs, ys, \"-o\", color=\"yellow\", markersize=2, linewidth=1)\n",
    "    ax.scatter([xs[0]], [ys[0]], c=\"lime\", s=36, marker=\"^\", label=\"start\")\n",
    "    ax.scatter([xs[-1]], [ys[-1]], c=\"magenta\", s=30, label=\"end\")\n",
    "ax.scatter(\n",
    "    [sx],\n",
    "    [sy],\n",
    "    marker=\"s\",\n",
    "    s=60,\n",
    "    facecolors=\"none\",\n",
    "    edgecolors=\"red\",\n",
    "    linewidths=1.5,\n",
    "    label=\"source\",\n",
    ")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_title(\"Run/Tumble TD with runner: final frame with trajectory\")\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action counts and time series\n",
    "run_count = int(np.sum(np.array(actions) == 0))\n",
    "tumble_count = int(np.sum(np.array(actions) == 1))\n",
    "print(\"RUN:\", run_count, \"TUMBLE:\", tumble_count)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax[0].bar([\"RUN\", \"TUMBLE\"], [run_count, tumble_count], color=[\"#4caf50\", \"#ff9800\"])\n",
    "ax[0].set_title(\"Action counts\")\n",
    "ts = np.arange(len(concs))\n",
    "ax[1].plot(ts, concs, label=\"c\")\n",
    "ax[1].plot(ts, dcs, label=\"dc\")\n",
    "ax[1].set_title(\"Concentration and dC\")\n",
    "ax[1].legend()\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
