{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Runner Demo (setup-only parity)\n",
    "\n",
    "This notebook mirrors the deterministic temporal-gradient demo. The runner is used only to simplify setup (building env + policy); stepping matches the non-runner demo: policy.select_action → env.step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure repo 'src' is on sys.path when running from notebooks/\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "repo_root = pathlib.Path.cwd()\n",
    "if not (repo_root / \"src\").exists():\n",
    "    repo_root = repo_root.parent\n",
    "sys.path.insert(0, str(repo_root / \"src\"))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "mpl.use(\"module://matplotlib_inline.backend_inline\")\n",
    "set_matplotlib_formats(\"png\")\n",
    "from IPython.display import display\n",
    "\n",
    "import plume_nav_sim as pns\n",
    "from plume_nav_sim.compose import SimulationSpec, PolicySpec, prepare\n",
    "from plume_nav_sim.policies import TemporalDerivativeDeterministicPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build env + deterministic TD policy via compose; step manually for parity with demos\n",
    "spec = SimulationSpec(\n",
    "    grid_size=(64, 64),\n",
    "    source_location=(48, 48),\n",
    "    start_location=(16, 16),\n",
    "    max_steps=500,\n",
    "    render=True,\n",
    "    policy=PolicySpec(\n",
    "        builtin=\"deterministic_td\", kwargs={\"threshold\": 1e-6, \"alternate_cast\": True}\n",
    "    ),\n",
    "    seed=123,\n",
    ")\n",
    "env, policy = prepare(spec)\n",
    "\n",
    "# Manual loop: policy.select_action → env.step (no runner.stream), matching non-runner demo\n",
    "obs, info = env.reset(seed=spec.seed)\n",
    "policy.reset(seed=spec.seed)\n",
    "positions = []\n",
    "total_reward = 0.0\n",
    "for _ in range(env.max_steps):\n",
    "    a = policy.select_action(obs, explore=False)\n",
    "    obs, reward, term, trunc, step_info = env.step(a)\n",
    "    total_reward += float(reward)\n",
    "    pos = step_info.get(\"agent_xy\") if isinstance(step_info, dict) else None\n",
    "    if pos is not None:\n",
    "        positions.append(tuple(pos))\n",
    "    if term or trunc:\n",
    "        break\n",
    "\n",
    "# Final frame and overlay\n",
    "frame = env.render(\"rgb_array\")\n",
    "grid_w, grid_h = getattr(env, \"grid_size\", (frame.shape[1], frame.shape[0]))\n",
    "sx, sy = getattr(env, \"source_location\", (grid_w // 2, grid_h // 2))\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.imshow(frame)\n",
    "ax.set_xlim(0, grid_w)\n",
    "ax.set_ylim(grid_h, 0)  # invert y so row 0 is at top\n",
    "if positions:\n",
    "    xs = [p[0] for p in positions]\n",
    "    ys = [p[1] for p in positions]\n",
    "    ax.plot(xs, ys, \"-o\", color=\"yellow\", markersize=2, linewidth=1)\n",
    "    ax.scatter([xs[0]], [ys[0]], c=\"lime\", s=36, marker=\"^\", label=\"start\")\n",
    "    ax.scatter([xs[-1]], [ys[-1]], c=\"magenta\", s=30, label=\"end\")\n",
    "ax.scatter(\n",
    "    [sx],\n",
    "    [sy],\n",
    "    marker=\"s\",\n",
    "    s=60,\n",
    "    facecolors=\"none\",\n",
    "    edgecolors=\"red\",\n",
    "    linewidths=1.5,\n",
    "    label=\"source\",\n",
    ")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_title(\"Final frame with agent trajectory\")\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "print(\"Total reward:\", total_reward)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
