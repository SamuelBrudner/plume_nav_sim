{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Capture Pipeline: End-to-End Exploration\n",
    "\n",
    "This notebook demonstrates a minimal end-to-end run of the data capture pipeline, including:\n",
    "\n",
    "- Running the capture via the CLI entrypoint using a Hydra config (conf/data_capture).\n",
    "- Validating emitted artifacts with `validate_run_artifacts`.\n",
    "- Inspecting provenance (`manifest.json`) including git SHA and config hash.\n",
    "- Loading JSONL/Parquet for quick exploratory analysis and a small plot.\n",
    "\n",
    "> Runtime profile: small grid (8x8), 2 episodes, deterministic seed for fast execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, gzip, io\n",
    "\n",
    "# Resolve repo root heuristically for local runs\n",
    "repo = Path.cwd()\n",
    "if not (repo / \"src\").exists():\n",
    "    # Try parent (common when opening notebook directly)\n",
    "    if (Path.cwd().parent / \"src\").exists():\n",
    "        repo = Path.cwd().parent\n",
    "\n",
    "out_root = repo / \"notebooks\" / \"_data\"\n",
    "out_root.mkdir(parents=True, exist_ok=True)\n",
    "out_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run capture via CLI main() using Hydra config\n",
    "from plume_nav_sim.cli.capture import main as capture_main\n",
    "\n",
    "argv = [\n",
    "    \"--output\",\n",
    "    str(out_root),\n",
    "    \"--experiment\",\n",
    "    \"nb_demo\",\n",
    "    \"--seed\",\n",
    "    \"123\",\n",
    "    \"--config-name\",\n",
    "    \"data_capture/config\",\n",
    "    \"episodes=2\",\n",
    "    \"env.grid_size=[8,8]\",\n",
    "    \"env.max_steps=20\",\n",
    "    \"--parquet\",  # write parquet if pyarrow available\n",
    "]\n",
    "rc = capture_main(argv)\n",
    "assert rc == 0, f\"capture CLI failed with code {rc}\"\n",
    "rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover latest run directory\n",
    "exp_dir = out_root / \"nb_demo\"\n",
    "candidates = [p for p in exp_dir.iterdir() if p.is_dir() and p.name.startswith(\"run-\")]\n",
    "assert candidates, f\"No run directory found in {exp_dir}\"\n",
    "run_dir = max(candidates, key=lambda p: p.stat().st_mtime)\n",
    "run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate artifacts with Pandera\n",
    "from plume_nav_sim.data_capture.validate import validate_run_artifacts\n",
    "\n",
    "report = validate_run_artifacts(run_dir)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect provenance manifest: config hash, env config, git SHA\n",
    "manifest = json.loads((run_dir / \"manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "{\n",
    "    \"experiment\": manifest.get(\"experiment\"),\n",
    "    \"run_id\": manifest.get(\"run_id\"),\n",
    "    \"git_sha\": manifest.get(\"git_sha\"),\n",
    "    \"config_hash\": manifest.get(\"config_hash\"),\n",
    "    \"schema_version\": manifest.get(\"schema_version\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load episodes using pandas if available; fallback to JSONL parsing\n",
    "episodes_path = run_dir / \"episodes.parquet\"\n",
    "steps_path = run_dir / \"steps.parquet\"\n",
    "use_pandas = True\n",
    "try:\n",
    "    import pandas as pd  # type: ignore\n",
    "except Exception:\n",
    "    use_pandas = False\n",
    "\n",
    "if use_pandas and episodes_path.exists():\n",
    "    episodes_df = pd.read_parquet(episodes_path)\n",
    "elif use_pandas:\n",
    "    episodes_df = pd.read_json(\n",
    "        run_dir / \"episodes.jsonl.gz\", lines=True, compression=\"gzip\"\n",
    "    )\n",
    "else:\n",
    "    # Lightweight fallback: count episodes via JSONL\n",
    "    with gzip.open(run_dir / \"episodes.jsonl.gz\", \"rt\", encoding=\"utf-8\") as fh:\n",
    "        episodes_df = [json.loads(l) for l in fh if l.strip()]\n",
    "\n",
    "type(episodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple exploratory plot: total steps per episode (if pandas/matplotlib available)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    if isinstance(episodes_df, pd.DataFrame):\n",
    "        episodes_df[[\"episode_id\", \"total_steps\"]].set_index(\"episode_id\").plot(\n",
    "            kind=\"bar\", legend=False\n",
    "        )\n",
    "        plt.title(\"Total Steps per Episode\")\n",
    "        plt.ylabel(\"steps\")\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        # Fallback: basic text output\n",
    "        print(\"Episodes:\", len(episodes_df))\n",
    "        print(\"Keys:\", list(episodes_df[0].keys()) if episodes_df else [])\n",
    "except Exception as e:\n",
    "    print(\"Plotting skipped:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- This notebook uses Hydra configs under `conf/data_capture`.\n",
    "- Provenance is captured in `manifest.json` (config hash, git SHA, schema version).\n",
    "- For faster loading, install the `data` extras to enable Parquet export/reads.\n",
    "\n",
    "Render to HTML for docs:\n",
    "```bash\n",
    "make nb-render\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
