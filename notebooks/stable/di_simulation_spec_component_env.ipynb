{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Stable DI: SimulationSpec + Component Environment\n",
    "\n",
    "This notebook demonstrates two stable ways to build and run plume navigation environments:\n",
    "\n",
    "- Create a component-based environment via the DI factory (`create_component_environment`)\n",
    "- Build an `(env, policy)` pair from a `SimulationSpec` using `prepare()` â€” including spec-declared observation wrappers\n",
    "\n",
    "> Headless-safe: no interactive rendering required; prints basic info during short runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# Basic environment info (optional)\n",
    "import plume_nav_sim as pns\n",
    "\n",
    "info = pns.get_package_info(include_registration_status=False)\n",
    "info[\"package_name\"], info[\"package_version\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1) Component environment via DI factory\n",
    "\n",
    "Create a fully-configured environment using `create_component_environment(...)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plume_nav_sim.envs.factory import create_component_environment\n",
    "\n",
    "env = create_component_environment(\n",
    "    grid_size=(32, 32),\n",
    "    goal_location=(16, 16),\n",
    "    action_type=\"discrete\",  # or 'oriented' / 'run_tumble'\n",
    "    observation_type=\"concentration\",  # scalar odor at agent position\n",
    "    reward_type=\"sparse\",  # success when within goal_radius\n",
    "    plume_sigma=10.0,\n",
    "    render_mode=None,\n",
    ")\n",
    "obs, info = env.reset(seed=42)\n",
    "print(\"reset info keys:\", sorted(info.keys()))\n",
    "\n",
    "steps = 0\n",
    "terminated = truncated = False\n",
    "while not (terminated or truncated) and steps < 10:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    steps += 1\n",
    "print(\"component env steps:\", steps, \"terminated=\", terminated, \"truncated=\", truncated)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2) Spec-first composition with SimulationSpec\n",
    "\n",
    "Define runtime behavior in one place with `SimulationSpec`, including optional observation wrappers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plume_nav_sim.compose import SimulationSpec, PolicySpec, WrapperSpec, prepare\n",
    "\n",
    "# Declare a simple wrapper: core 1-back odor history -> observation becomes [c_prev, c_now]\n",
    "nback = WrapperSpec(\n",
    "    spec=\"plume_nav_sim.observations.history_wrappers:ConcentrationNBackWrapper\",\n",
    "    kwargs={\"n\": 2},\n",
    ")\n",
    "\n",
    "sim = SimulationSpec(\n",
    "    grid_size=(32, 32),\n",
    "    source_location=(16, 16),\n",
    "    max_steps=30,\n",
    "    goal_radius=5.0,\n",
    "    plume_sigma=12.0,\n",
    "    action_type=\"discrete\",\n",
    "    observation_type=\"concentration\",\n",
    "    reward_type=\"step_penalty\",\n",
    "    render=False,\n",
    "    seed=123,\n",
    "    policy=PolicySpec(builtin=\"deterministic_td\"),\n",
    "    observation_wrappers=[nback],\n",
    ")\n",
    "\n",
    "env, policy = prepare(sim)\n",
    "obs, info = env.reset(seed=sim.seed)\n",
    "print(\"wrapped observation shape:\", getattr(env.observation_space, \"shape\", None))\n",
    "\n",
    "total = 0.0\n",
    "for t in range(10):\n",
    "    # Policies support either select_action(obs, explore=False) or callable-style\n",
    "    act = getattr(policy, \"select_action\", policy)(obs)\n",
    "    obs, r, done, trunc, info = env.step(act)\n",
    "    total += float(r)\n",
    "    if done or trunc:\n",
    "        break\n",
    "print(\"spec episode steps:\", t + 1, \"total reward=\", total)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- `create_component_environment(...)` assembles a DI-backed environment from curated defaults and options.\n",
    "- `SimulationSpec` forwards environment parameters to `plume_nav_sim.make_env(...)` and applies wrappers via dotted-path.\n",
    "- `prepare(sim)` performs a policy vs environment action-space subset check and calls `policy.reset(seed=...)` when available.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
