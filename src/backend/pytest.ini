[pytest]
# Minimum pytest version requirement ensuring compatibility with modern testing features,
# Python 3.10+ support, and advanced fixture management capabilities
minversion = 8.0

# Primary test directory specification for pytest discovery and execution within backend
# project structure following standard pytest conventions
testpaths = tests

# Test file patterns for comprehensive test discovery supporting both standard pytest 
# naming (test_*.py) and alternative naming (*_test.py) conventions
python_files = test_*.py *_test.py

# Test class patterns supporting both prefix (Test*) and suffix (*Test) naming
# conventions for flexible test organization and discovery
python_classes = Test* *Test

# Test function pattern following standard pytest convention for function-based
# test discovery and execution
python_functions = test_*

# Additional pytest options including short test summary (-ra), strict marker
# enforcement (--strict-markers), strict configuration validation (--strict-config),
# concise traceback format (--tb=short), and slowest test reporting
# (--durations=10 --durations-min=1.0)
addopts = -ra --strict-markers --tb=short --durations=10 --durations-min=1.0 --cov=plume_nav_sim --cov-report=term-missing --cov-report=html:tests/coverage/html --cov-report=xml:tests/coverage/coverage.xml --cov-branch --cov-fail-under=90 -x --maxfail=5 --disable-warnings

# Comprehensive test markers for categorizing and selectively executing different
# types of tests during development and CI/CD workflows with specific test targeting capabilities
markers =
    unit: marks unit tests for individual component validation
    integration: marks integration tests for cross-component validation
    performance: marks performance tests with timing and resource monitoring
    slow: marks slow-running tests requiring extended execution time
    reproducibility: marks reproducibility tests with deterministic seeding
    edge_case: marks edge case tests with boundary conditions
    memory: marks memory usage tests with leak detection
    scalability: marks scalability tests across different grid sizes
    regression: marks regression tests for performance trend analysis
    concurrent: marks concurrent execution tests with thread safety
    benchmark: marks benchmark tests with statistical analysis
    rendering: marks rendering system tests with visualization validation
    api_compliance: marks Gymnasium API compliance tests
    functional: marks functional requirement validation tests
    stress: marks stress tests with extreme parameter validation
    flaky: marks potentially unstable tests requiring retry logic
    gpu: marks tests requiring GPU acceleration (skipped if unavailable)
    network: marks tests requiring network connectivity
    timeout: marks tests with extended execution time requirements
    parametrized: marks parametrized tests with multiple input combinations

# Warning filter configuration treating most warnings as errors for strict testing
# while ignoring known matplotlib and gymnasium warnings that don't affect functionality
filterwarnings =
    error
    ignore::UserWarning:matplotlib.*
    ignore::DeprecationWarning:gymnasium.*
    ignore::PendingDeprecationWarning
    ignore::RuntimeWarning:numpy.*
    ignore::FutureWarning:gymnasium.spaces.*
    ignore::ResourceWarning
    ignore:.*backend.*:UserWarning:matplotlib.*

# Enable live logging to console during test execution for real-time debugging
# and development feedback
log_cli = true

# Console logging level set to INFO for comprehensive test execution feedback
# without verbose debug output
log_cli_level = INFO

# Structured console log format with timestamp, level, logger name, and message
# for clear test execution tracking
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s

# Console log timestamp format for precise test execution timing and debugging analysis
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Test execution log file for persistent logging and comprehensive test run analysis
log_file = tests/logs/pytest.log

# File logging level set to DEBUG for comprehensive test execution analysis
# and troubleshooting
log_file_level = DEBUG

# Detailed file log format with timestamp, level, filename, line number, function name,
# and message for comprehensive debugging support
log_file_format = %(asctime)s [%(levelname)8s] %(filename)s:%(lineno)d %(funcName)s(): %(message)s

# File log timestamp format matching console format for consistent temporal analysis
log_file_date_format = %Y-%m-%d %H:%M:%S

# Console output style showing progress indicators for test execution feedback
# during long-running test suites
console_output_style = progress

# JUnit XML output format for CI/CD integration and test result reporting
# in continuous integration pipelines
junit_family = xunit2

# JUnit XML suite name for clear identification in CI/CD reporting and test result analysis
junit_suite_name = plume_nav_sim_test_suite

# JUnit XML output file location for CI/CD pipeline integration
junit_logging = all
junit_log_passing_tests = true

# Default test timeout of 300 seconds preventing indefinite test execution
# and ensuring robust CI/CD pipeline behavior

# Pytest cache configuration for improved test execution performance
cache_dir = tests/.pytest_cache

# Test output configuration for enhanced debugging and analysis
tb = short
showlocals = true
verbosity = 1

# Test collection configuration for comprehensive test discovery optimization
collect_ignore_glob = 
    *.pyc
    __pycache__
    .pytest_cache
    build
    dist
    *.egg-info
    .tox
    .venv
    venv
    .git
    node_modules
    *.log
    *.tmp

# Test execution order configuration for consistent and predictable test runs

# Directories to exclude from recursive test discovery preventing collection
# in build artifacts, version control, and dependency directories
norecursedirs = *.egg .eggs dist build docs .tox .git __pycache__ .pytest_cache node_modules .mypy_cache .coverage htmlcov

[coverage:run]
# Source code directory for coverage analysis focusing on main package implementation
# excluding test code
source = plume_nav_sim

# Branch coverage analysis ensuring comprehensive test coverage including
# conditional logic paths and edge cases
branch = True

# Files and directories to exclude from coverage analysis including test files,
# setup scripts, and cache directories
omit = 
    */tests/*
    */test_*
    setup.py
    */conftest.py
    */__pycache__/*
    */.*
    */venv/*
    */virtualenv/*
    */build/*
    */dist/*
    */.pytest_cache/*
    */.coverage
